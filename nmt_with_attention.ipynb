{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# **어텐션을 사용한 인공 신경망 기계 번역**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 연습은 스페인어를 영어로 변역하기 위해 시퀀스-투-시퀀스 (seq2seq) 모델을 훈련시킨다. 또한 이 연습은 시퀀스-투-시퀀스 모델의 사전적인 지식을 요구하는 심화된 예제이다.\n",
    "\n",
    "이 노트북에서 신경망 기계 번역 모델을 훈련하면 *\"¿todavia estan en casa?\"* 와 같은 스페인 문장을 입력했을 때 *\"are you still at home?\"* 처럼 영어로 번역된 문장을 얻는다.\n",
    "\n",
    "번역의 질은 간단한 예제로는 타당하지만 시각화된 어텐션 플롯은 아마 더 흥미로울 것이다. 아래의 플롯은 모델을 훈련하는 동안에 입력 문장의 각 단어가 갖고 있는 모델 어텐션을 시각화하여 보여준다:\n",
    "\n",
    "<img src='https://tensorflow.org/images/spanish-english.png' alt='spanish-english attention plot'>\n",
    "\n",
    "노트: 이 예제를 단일 P100 GPU에서 실행하기 위해서는 약 10분 정도 걸린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **데이터셋 다운로드하고 준비하기**\n",
    "\n",
    "http://www.manythings.org/anki/ 에서 제공한 언어 데이터셋을 사용한다. 이 데이터셋은 언어 번역의 쌍이 다음과 같은 형식으로 포함된다:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "다양한 언어가 이용 가능하지만 이 예제에서는 영어-스페인 데이터셋을 사용한다. 편의를 위해서 이 데이터셋의 복사본을 Google Cloud에서 호스팅 했지만 직접 다운로드해야 한다. 데이터셋을 다운로드한 후에 데이터를 준비하고자 다음의 단계를 수행한다.\n",
    "\n",
    "1. 각 문장에 *start*와 *end* 토큰을 추가한다.\n",
    "2. 특정 문자를 제거함으로써 문장을 정리한다.\n",
    "3. 단어 인덱스와 아이디(ID) 인덱스를 생성한다. (단어 → 아이디(ID), 아이디(ID) → 단어로 매핑된 딕셔너리).\n",
    "4. 각 문장을 입력층의 최대 길이만큼 패딩(padding)을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 파일을 다운로드한다.\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True\n",
    ")\n",
    "path_to_file = os.path.dirname(path_to_zip) + '/spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "# 유니코드 파일을 아스키 코드 파일로 변환한다.\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower())\n",
    "    # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성한다.\n",
    "    # 예시: 'he is a boy.' => 'he is a boy . '\n",
    "    # 참고: https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r'([?.!,¿])', r' \\1 ', w)\n",
    "    # (a-z, '.', '?', '!', ',')을 제외한 모든 것을 공백으로 대체한다.\n",
    "    w = re.sub(r'[^a-z?.!,¿]+', ' ', w)\n",
    "    w = w.strip()\n",
    "    # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서 문장에 start와 end 토큰을 추가한다.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = 'May I borrow-this book?'\n",
    "sp_sentence = '¿Puedo tomar prestado este libro?'\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "# 1. 문장에 있는 억양을 제거한다.\n",
    "# 2. 불필요한 문자를 제거하여 문장을 정리한다.\n",
    "# 3. 다음과 같은 형식으로 문장의 쌍을 반환한다: [영어, 스페인어]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.utils.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # 전처리된 타겟 문장과 입력 문장 쌍을 생성한다.\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **더 빠른 실행을 위해 데이터셋의 크기 제한하기(선택)**\n",
    "\n",
    "10만개 이상의 문장이 있는 완전한 데이터셋을 훈련하는 것은 오랜 시간이 걸린다. 훈련 속도를 높이기 위해서 데이터셋의 크기를 3만개의 문장으로 제한한다. (물론, 번역의 질은 데이터가 적어질수록 저하된다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 언어 데이터셋을 아래의 크기로 제한하여 훈련과 검증을 수행한다.\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "# 타겟 텐서와 입력 텐서의 최대 길이를 계산한다.\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 집합과 검증 집합을 80대 20으로 분리한다.\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "    input_tensor, target_tensor, test_size=0.2\n",
    ")\n",
    "# 훈련 집합과 검증 집합의 데이터 크기를 출력한다.\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print(f'{t} ----> {lang.index_word[t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "1833 ----> compra\n",
      "13 ----> la\n",
      "4734 ----> version\n",
      "2502 ----> completa\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "272 ----> buy\n",
      "13 ----> the\n",
      "473 ----> full\n",
      "3047 ----> version\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print('Input Language; index to word mapping')\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print('\\nTarget Language; index to word mapping')\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **tf.data 데이터셋 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 인코더 모델과 디코더 모델 쓰기\n",
    "\n",
    "어텐션(attention)을 가진 인코더-디코더 모델을 수행한다. 어텐션(attention)은 TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt)에서 읽을 수 있다. 이 예제는 더 최신의 API 집합을 사용한다. 이 노트북은 seq2seq 튜토리얼로부터 [어텐션 방정식](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism)을 수행한다. 아래의 다이어그램은 각각의 입력 단어가 어텐션 메커니즘에 의해 가중치가 할당된 모습이다. 이러한 어텐션 메커니즘은 디코더가 문장에서 다음 단어를 예측하기 위해 사용된다. 아래의 그림과 공식은 [Luong's paper](https://arxiv.org/abs/1508.04025v5)에서 나온 어텐션 메커니즘의 예시이다.\n",
    "\n",
    "<img src='https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg' width='500' alt='attention mechanism'>\n",
    "\n",
    "입력은 *(batch_size, max_length, hidden_size)* 의 형태로 이루어진 인코더 결과와 *(batch_size, hidden_size)* 쌍으로 이루어진 인코더 은닉 상태(hidden state)를 제공하는 인코더 모델을 통해 입력된다.\n",
    "\n",
    "아래의 공식은 위에서 사용한 방정식을 나타낸 것이다:\n",
    "\n",
    "<img src='https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg' alt='attention equation 0' width='800'>\n",
    "<img src='https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg' alt='attention equation 1' width='800'>\n",
    "\n",
    "이 튜토리얼은 인코더를 위해 [Bahdanau 어텐션](https://arxiv.org/pdf/1409.0473.pdf)을 사용한다. 단순화된 형태로 쓰기 전에 표기법을 아래와 같이 정의한다:\n",
    "\n",
    "* FC = 완전 연결(Dense) 층\n",
    "* EO = 인코더 결과\n",
    "* H = 은닉 상태(hidden state)\n",
    "* X = 디코더에 대한 입력\n",
    "\n",
    "그리고 다음은 슈도코드이다:\n",
    "\n",
    "* `스코어(score)는 FC(tanh(FC(EO) + FC(H)))`로 계산한다.\n",
    "* `어텐션 가중치는 softmax(score, axis = 1)`로 계산한다. 기본적으로 소프트맥스는 마지막 축을 적용하지만 스코어(score)의 형태가 *(batch_size, max_length, hidden_size)* 이기 때문에 *두번째 축*을 적용한다. `Max_length`은 입력의 길이이다. 각각의 입력에 가중치를 할당하려고 시도하기 때문에 소프트맥스는 그 축을 적용할 수 있다.\n",
    "* `컨텍스트 벡터(context vector)는 sum(어텐션 가중치 * EO, axis = 1)`로 계산한다. 위와 같은 이유로 두번째 축을 선택한다.\n",
    "* `임베딩 결과(embedding output)`는 디코더 X에 대한 입력이 임베딩 층을 통과한 결과이다.\n",
    "* `병합된 벡터(merged vector)는 concat(임베딩 결과, 컨텍스트 백터(context vector))`와 같다.\n",
    "* 그런 다음 병합된 벡터는 GRU에 주어진다.\n",
    "\n",
    "매 단계마다 모든 벡터의 형태는 코드 내 주석에 명시되어 있다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units, recurrent_initializer='glorot_uniform', return_sequences=True, return_state=True\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "# 샘플 입력\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print(f'Encoder output shape: (batch size, sequence length, units) {sample_output.shape}')\n",
    "print(f'Encoder Hidden state shape: (batch size, units) {sample_hidden.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # 쿼리 은닉 상태(query hidden state)는 (batch_size, hidden size)쌍으로 이루어진다.\n",
    "        # query_with_time_axis은 (batch_size, 1, hidden size)쌍으로 이루어진다.\n",
    "        # values는 (batch_size, max_len, hidden size)쌍으로 이루어진다.\n",
    "        # 스코어(score)계산을 위해 덧셈을 수행하고자 시간 축을 확장하여 아래의 과정을 수행한다.\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        # score는 (batch_size, max_length, 1)쌍으로 이루어진다.\n",
    "        # score를 self.V에 적용하기 때문에 마지막 축에 1을 얻는다.\n",
    "        # self.V에 적용하기 전에 텐서는 (batch_size, max_length, units)쌍으로 이루어진다.\n",
    "        score = self.V(tf.keras.activations.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        # attention_weights는 (batch_size, max_length, 1)쌍으로 이루어진다.\n",
    "        attention_weights = tf.nn.softmax(score, 1)\n",
    "        # 덧셈 이후 컨텍스트 벡터(context_vector)는 (batch_size, hidden_size)쌍으로 이루어진다.\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.math.reduce_sum(context_vector, 1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "print(f'Attention result shape: (batch size, units) {attention_result.shape}')\n",
    "print(f'Attention weights shape: (batch_size, sequence_length, 1) {attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super().__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.dec_units, recurrent_initializer='glorot_uniform', return_sequences=True, return_state=True\n",
    "        )\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # 어텐션을 사용한다.\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output는 (batch_size, max_length, hidden_size)쌍으로 이루어진다.\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # 임베딩층을 통과한 후 x는 (batch_size, 1, embedding_dim)쌍으로 이루어진다.\n",
    "        x = self.embedding(x)\n",
    "        # 컨텍스트 벡터와 임베딩 결과를 결합한 이후 x의 형태는 (batch_size, 1, embedding_dim + hidden_size)쌍으로 이루어진다.\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], -1)\n",
    "        # 위에서 결합된 벡터를 GRU에 전달한다.\n",
    "        output, state = self.gru(x)\n",
    "        # output은 (batch_size * 1, hidden_size)쌍으로 이루어진다.\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # output은 (batch_size, vocab)쌍으로 이루어진다.\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "print(f'Decoder output shape: (batch_size, vocab size) {sample_decoder_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 최적화 함수와 손실 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.math.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 체크포인트 (객체 기반 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join('.', checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델 훈련하기\n",
    "\n",
    "1. *인코더 결과*와 *인코더 은닉 상태(hidden state)* 를 반환하는 *인코더*를 통해서 *입력*을 전달한다.\n",
    "2. 인코더 결과, 인코더 은닉 상태(hidden state), 디코더 입력(*start 토큰*)을 디코더에 전달한다.\n",
    "3. 전달 받은 값을 통해 디코더는 *예측 값*과 *디코더 은닉 상태(hidden state)* 를 반환한다.\n",
    "4. 그 다음에 디코더 은닉 상태(hidden state)가 다시 모델에 전달되고 예측 값을 사용하여 손실을 계산한다.\n",
    "5. 디코더에 대한 다음 입력을 결정하기 위해서 *교사 강요(teacher forcing)* 를 사용한다.\n",
    "6. *교사 강요(teacher forcing)* 는 *타겟 단어*가 디코더에 *다음 입력*으로 전달하기 위한 기술이다.\n",
    "7. 마지막 단계는 그레디언트(gradients)를 계산하여 이를 옵티마이저(optimizer)와 역전파(backpropagate)에 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)한다.\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # enc_output를 디코더에 전달한다.\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            # 교사 강요(teacher forcing)를 사용한다.\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6387\n",
      "Epoch 1 Batch 100 Loss 2.1535\n",
      "Epoch 1 Batch 200 Loss 1.9115\n",
      "Epoch 1 Batch 300 Loss 1.7295\n",
      "Epoch 1 Loss 2.0372\n",
      "Time taken for 1 epoch 52.660651445388794 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# EPOCHS = 10\n",
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for batch, (inp, targ) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
    "    # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "    print(f'Epoch {epoch + 1} Loss {total_loss / steps_per_epoch:.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start} sec\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 번역하기\n",
    "\n",
    "* 평가 함수는 여기서 *교사 강요(teacher forcing)* 를 사용하지 못하는 것을 제외하고는 훈련 루프와 비슷하다. 각 마지막 시점(time step)에서 이전 디코더 인코더의 결과와 은닉 상태(hidden state)를 가진 예측 값을 디코더에 입력한다.\n",
    "* 모델이 *end 토큰을 예측할 때 예측하는 것을 중지한다.*\n",
    "* 그리고 *매 마지막 시점(time step)에 대한 어텐션 가중치*를 저장한다.\n",
    "\n",
    "노트: 인코더 결과는 하나의 입력에 대해 단 한 번만 계산됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.utils.pad_sequences([inputs], max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장한다.\n",
    "        attention_weights = tf.reshape(attention_weights, [-1])\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.math.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        # 예측된 ID를 모델에 다시 피드한다.\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "# 어텐션 가중치를 그리기 위한 함수이다.\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticks(np.arange(len(sentence)), sentence, **fontdict, rotation=90)\n",
    "    ax.set_yticks(np.arange(len(predicted_sentence)), predicted_sentence, **fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print(f'Input: {sentence}')\n",
    "    print(f'Predicted translation: {result}')\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ puedo tomar prestado este libro ? <end>\n",
      "Predicted translation: is you want ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(sp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
